---
title: "Modeling and Detection of PSOs"
author: "Richard Schweitzer"
date: "3/12/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is the supplemental Code for the book chapter "Definition, modeling and detection of saccades in the face of post-saccadic oscillations" by Richard Schweitzer and Martin Rolfs. 

## Using the Bouzat-Del Punta model to generate saccades with PSOs

Let's first look at the function to generate saccades with post-saccadic oscillations (PSOs). To do that, we need to source two functions first and you should have the package *deSolve* installed.

```{r}
library(deSolve)
source("hypergeom1F1.R") # hypergeometric function 1F1 from CharFun
source("PSO_fit.R") # all the relevant model formulas

# what's the time interval?
t_sac <- seq(0, 120)

# plot some random trajectories here:
plot(t_sac, PSO_fit(t_sac = t_sac, xm = 10, beta = 1, mu = 2, A = 0.04, 
                    gamma0 = 0.15, k0 = 0.032), col = "black", 
     xlab = "Time [ms]", ylab = "Position [dva]")
points(t_sac, PSO_fit(t_sac = t_sac, xm = 6, beta = 1, mu = 2, A = 0.04, 
                      gamma0 = 0.15, k0 = 0.032), col = "blue")
points(t_sac, PSO_fit(t_sac = t_sac, xm = 2, beta = 1, mu = 2, A = 0.04, 
                      gamma0 = 0.15, k0 = 0.032), col = "red")
lines(t_sac, x_t(t = t_sac, beta = 1, mu = 2, xm = 10, A = 0.04), col = "black")
lines(t_sac, x_t(t = t_sac, beta = 1, mu = 2, xm = 6, A = 0.04), col = "blue")
lines(t_sac, x_t(t = t_sac, beta = 1, mu = 2, xm = 2, A = 0.04), col = "red")
legend(100, 2, legend=c("xm=10", "xm=6", "xm=2"),
       col=c("black", "blue", "red"), lty=1, cex=0.8)

# Replicate Fig. 3 in Bouzat et al. (2018), at least for xm=16
plot(t_sac, PSO_fit(t_sac = t_sac, xm = 16, beta = 1, mu = 2, A = 0.04, 
                    gamma0 = 0.15, k0 = 0.032, c = 0, d = 0), 
     col = "black", type = "l", ylim = c(0, 17), 
     xlab = "Time [ms]", ylab = "Position [dva]")
lines(t_sac, PSO_fit(t_sac = t_sac, xm = 16, beta = 1, mu = 2, A = 0.04, 
                     gamma0 = 0.15, k0 = 0.032, c = 0.5, d = 3), 
      col = "red", type = "l")
legend(60, 5, legend=c("constant (c=0, d=0)", "force-dependent (c=0.5, d=3)"),
       col=c("black", "red"), lty=1, cex=0.8)

# Replicate Fig. 9 in Del Punta et al. (2019)
plot(t_sac, PSO_fit(t_sac = t_sac, xm = 10, beta = 1, mu = 2, A = 0.036, 
                    gamma0 = 0.14, k0 = 0.04, c = 0.5, d = 3, 
                    viscosity = FALSE), col = "blue", type = "l", ylim = c(0, 12), 
     xlab = "Time [ms]", ylab = "Position [dva]")
lines(t_sac, PSO_fit(t_sac = t_sac, xm = 10, beta = 1, mu = 2, A = 0.036, 
                     gamma0 = 0.07, k0 = 0.035, c = 1, d = 5, 
                     viscosity = TRUE), col = "red")
lines(t_sac, x_t(t = t_sac, beta = 1, mu = 2, xm = 10, A = 0.036), col = "black")
legend(60, 5, legend=c("x(t)", "x(t)+y(t) force-dependent (c=0.5, d=3)", "x(t)+y(t) viscosity (c=1, d=5)"),
       col=c("black", "blue", "red"), lty=1, cex=0.8)
```

Okay, great, shall we look at an empirically measured saccade? Here we load a random saccade, in fact, one that is from a manually coded database by Nystrom and colleagues, found here: http://dev.humlab.lu.se/www-transfer/people/marcus-nystrom/annotated_data.zip

```{r}
load("some_sac.rda")
# what does this saccade look like?
plot(some_sac$time_sacon, some_sac$x_sacon, col = "darkgreen", 
     type = "p", xlab = "Time after saccade onset [ms]", ylab = "Position [dva]")
points(some_sac$time_sacon, some_sac$y_sacon, col = "darkblue")
legend(-40, -8, legend=c("X coord", "Y coord"),
       col=c("darkgreen", "darkblue"), pch = c(1, 1))

# alternatively, a trajectory that we can fit
plot(some_sac$time_sacon[some_sac$time_sacon>=0], 
     some_sac$dist_sacon[some_sac$time_sacon>=0], 
     col = "black", type = "p", xlab = "Time after saccade onset [ms]", ylab = "Position [dva]")
```

Now try fitting Method 1. Run an optimizer with a grid of different starting parameters.

```{r}
library(minpack.lm) # for Levenberg-Marquart
library(data.table)
library(assertthat)

# this is the function for running the optimizer with a grid of starting parameters:
source("get_best_NLS.R")

# options for fitting?
nls_options <- nls.lm.control(maxiter = 100, nprint = 0)
# model formula as a string:
nls_model_form <- "dist_sacon ~ PSO_fit(time_sacon, xm, beta=1, mu=2, A, gamma0, k0, c=0, d=0)"
# run:
best_PSO_model <- get_best_NLS(df = some_sac[some_sac$time_sacon>=0, ], 
                               model_control = nls_options, 
                               model_form = nls_model_form,
                               start_params_low = c(xm = 7, A = 0.02, gamma0 = 0.05, k0 = 0.01),
                               start_params_high = c(xm = 12, A = 0.08, gamma0 = 0.2, k0 = 0.1),
                               absolute_lowest = c(xm = 10e-6, A = 10e-6, gamma0 = 10e-6, k0 = 10e-6),
                               start_params_n = 3, use_robust = FALSE, 
                               debug_mode = FALSE)
nrow(best_PSO_model$start_params) # number of all combinations of starting parameters
best_PSO_model$best_fit # the best model

# what does this look like?
plot(some_sac$time_sacon[some_sac$time_sacon>=0],  # data
     some_sac$dist_sacon[some_sac$time_sacon>=0], 
     col = "black", type = "p", xlab = "Time [ms]", ylab = "Position [dva]")
lines(some_sac$time_sacon[some_sac$time_sacon>=0], # fit
     predict(best_PSO_model$best_fit), 
     col = "black")
lines(some_sac$time_sacon[some_sac$time_sacon>=0], # eyeball prediction
      x_t(t = some_sac$time_sacon[some_sac$time_sacon>=0], 
          xm = best_PSO_model$best_params$xm, A = best_PSO_model$best_params$A, beta = 1, mu = 2), 
      col = "black", lty = "dotted")
legend(60, 4, legend=c("fit of pupil data, x(t)+y(t)", "prediction of eyeball data, x(t)"),
       col=c("black", "black"), lty=c("solid", "dotted"), cex=0.8)
```

Fitting method 2. First run a (coarse) grid-search, find the best fitting parameters and then use those as starting parameters in a refinement step fit

```{r}
library(nls2) # for grid search

# what's most likely the amplitude of the saccade? Just to have a reasonable start for xm
likely_amp <- some_sac$dist_sacon[some_sac$time_sacoff==0]

# step 1: brute-force starting parameters
# define the grid for the search. it's rather coarse here, but it can always be expanded
brute_st1 <- expand.grid(xm = seq(likely_amp-0.2, likely_amp+0.2, len = 4), 
                         mu = seq(1.5, 3, len = 4), A = seq(0.02, 0.06, len = 4),
                         gamma0 = seq(0.1, 0.2, len = 4), k0 = seq(0.01, 0.04, len = 4) )
head(brute_st1)
# run the grid-search here
brute_fit <- nls2(data = some_sac[some_sac$time_sacon>=0, ],
                  formula = dist_sacon ~ PSO_fit(time_sacon, xm, beta=1,
                                                 mu, A, gamma0, k0, c=0, d=0,
                                                 viscosity = FALSE,
                                                 use_method = "euler"), # Euler should be fastest method
                  start = brute_st1, algorithm = "brute-force")
brute_fit
brute_fit_coef <- as.numeric(coefficients(brute_fit))

# step 2: refine fit with Levenberg Marquart
refined_fit <- nlsLM(data = some_sac[some_sac$time_sacon>=0, ], 
                     control = nls.lm.control(maxiter = 500, nprint = 1),
                     formula = dist_sacon ~ PSO_fit(time_sacon, xm, beta=1, 
                                                    mu, A, gamma0, k0, c=0, d=0,
                                                    viscosity = FALSE),
                     start = c(xm = brute_fit_coef[1], mu = brute_fit_coef[2], A = brute_fit_coef[3], 
                               gamma0 = brute_fit_coef[4], k0 = brute_fit_coef[5]),
                     lower = c(xm = 10e-6, mu=1, A = 10e-6, 
                               gamma0 = 10e-6, k0 = 10e-6))
refined_fit
# fitting method 1 vs 2, that is without vs with mu
anova(best_PSO_model$best_fit, # Fitting method 1, fixed mu 
      refined_fit) # Fitting method 2, refined fit, free mu

## plot the predictions of the brute and refined fits
plot(some_sac$time_sacon[some_sac$time_sacon>=0],  # data
     some_sac$dist_sacon[some_sac$time_sacon>=0], 
     col = "black", type = "p", xlab = "Time [ms]", ylab = "Position [dva]")
lines(some_sac$time_sacon[some_sac$time_sacon>=0], # brute fit
     predict(brute_fit), 
     col = "blue", lty = "dashed")
lines(some_sac$time_sacon[some_sac$time_sacon>=0], # refined fit
      predict(refined_fit), 
      col = "red", lty = "solid")
legend(60, 4, legend=c("grid-search fit", "LM-refined fit"),
       col=c("blue", "red"), lty=c("dashed", "solid"), cex=0.8)
```

## The saccade simulator

Using the model function above, we can simulate saccades with post-saccadic oscillations. But what about fixations? Can we simulate fixational drift? Yes, there is a model by Engbert and colleagues, see https://doi.org/10.1073/pnas.1102730108. It's implemented in the *self_avoiding_walk* function.

```{r}
library(ggplot2)
library(viridis)
source("self_avoiding_walk.R")
# discrete
walked_discrete <- self_avoiding_walk(n_steps = 100, 
                                      relax_rate = 0.01,
                                      L = 101, U_slope = 0.2, 
                                      U_m_sd=c(0.5, 0.2), 
                                      use_only_direct_neighbors = TRUE, 
                                      do_plot = TRUE, 
                                      do_final_smooth = FALSE)
# smooth version
walked_smooth <- self_avoiding_walk(n_steps = 100,  
                                    relax_rate = 0.01, 
                                    L = 101, U_slope = 0.2, 
                                    U_m_sd=c(0.5, 0.2), 
                                    use_only_direct_neighbors = TRUE, 
                                    do_plot = TRUE, 
                                    do_final_smooth = TRUE)
```

Now, there's a easy-to-use package, the saccade simulator. Here we simulate a sequence of two saccades. 

```{r, fig.width=16, fig.height=8}
source("saccade_simulator.R") # includes main function and aux functions

# Fixation characteristics
# fixation X, Y [pix], and duration [ms]
fixpos_xy <- matrix(data = c(150, 100, 150, 
                             750, 120, 280, 
                             500, 500, 200), 
                    nrow = 3, ncol = 3, byrow = TRUE)
# Saccade model parameters:
# beta, mu, A, gamma, k, c, d, viscosity; while xm is determined by fixation positions
sac_params <- matrix(data = c(1, 2.2, 0.04, 0.14, 0.013, 0.5, 3, FALSE, 
                              1, 2.2, 0.04, 0.14, 0.013, 0.5, 3, FALSE), 
                     nrow = 2, ncol = 8, byrow = TRUE)
# Fixation model parameters:
# relax_rate, U_slope, U_mean, U_sd, direct neighbors only
fix_params <- matrix(data = rep(c(0.01, 10, 0, 0, FALSE), 
                                3), 
                     nrow = 3, ncol = 5, byrow = TRUE)  
# Now run the saccade simulator:
simulator_results <- saccade_simulator(fixpos_xy = fixpos_xy, 
                                       sac_params = sac_params, 
                                       fix_params = fix_params, 
                                       pix_per_dva = 25, # pixels per degree, should be matched to setup
                                       detect_vel_criterion = 5, # ground-truth velocity criterion [dva/s]
                                       sampling_rate = 1000, # in Hz
                                       noise_to_saccades_sd = 0, # should Gaussian noise be added to saccades?
                                       smooth_to_fixation = TRUE, # FALSE: discrete, TRUE: smooth fixation data
                                       do_plot = TRUE) 
head(simulator_results[[1]]) # raw position data
head(simulator_results[[2]]) # fixation and saccade metrics
```

## Velocity-based saccade and PSO detection

We describe an add-on for the widely used Engbert-Kliegl algorithm for microsaccade detection (see http://read.psych.uni-potsdam.de/index.php?option=com_content&view=article&id=140:engbert-et-al-2015-microsaccade-toolbox-for-r&catid=26:publications&Itemid=34 for the original algorithm), which detects PSOs based on minimum velocity or direction inversion. We'll use that here on our just simulated data. 

```{r, fig.width=16, fig.height=8}
# STEP 1: Detect saccades with EK algorithm and we'll see how PSOs are detected as saccades
source("vecvel.R") # from MS toolbox. Transforms into 2D velocity space
source("microsacc.R") # from MS toolbox. Original algorithm
# Output:
#  [,1]   saccade onset [index]
#  [,2]   saccade offset [index]
#  [,3]   peak velocity (vpeak)
#  [,4]   horizontal component (dx, i.e., x[off]-x[on])
#  [,5]   vertical component (dy)
#  [,6]   horizontal amplitude (dX, i.e., x[max(x)]-x[min(x)])
#  [,7]   vertical amplitude (dY)
(original_EK_results <- microsacc(x = as.matrix(cbind(simulator_results[[1]]$x, simulator_results[[1]]$y)), 
                                  VFAC = 4, MINDUR = 5, SAMPLING = 1000))

# STEP 2: 1st Add-on. Detect clusters of saccades. 
# Note that this currently only implemented for the (most common) case of clusters of two saccades
# Here we'll merge the 2nd saccade with the 1st saccade to run PSO detection later.
source("check_for_sac_clustering.R")
(clustered_EK_results <- check_for_sac_clustering(sac_table = original_EK_results$table, 
                                                  n_cluster_samples = 20, # number of samples distance
                                                  do_what = 2)) # 0: do nothing, 1: eliminate 2nd sac, 2: merge

# STEP 3: 2nd Add-on. Run PSO detection the clustered saccade data. 
# The algorithm adds 4 columns to the saccade table
# [,8] direction-inversion sample index
# [,9] overall saccade direction in degrees
# [,10] minimum-velocity sample index
# [,11] minimum velocity detected
source("check_for_PSO.R")
(PSO_EK_results <- check_for_PSO(eye_x = simulator_results[[1]]$x, 
                                 eye_y = simulator_results[[1]]$y, 
                                 samp_rate = 1000, 
                                 em_table = clustered_EK_results, 
                                 direction_range = 60))

# PLOT the detection results:
par(mfrow=c(1,2)) 
# x 
plot(simulator_results[[1]]$time, simulator_results[[1]]$x, 
     xlab = "Time [ms]", ylab = "X position [pix]", 
     cex.lab = 1.2, cex.axis = 1.2)
abline(v = simulator_results[[1]]$time[PSO_EK_results[,1]], col = "black", lty = 2)
abline(v = simulator_results[[1]]$time[PSO_EK_results[,8]], col = "red")
abline(v = simulator_results[[1]]$time[PSO_EK_results[,10]], col = "blue")
abline(v = simulator_results[[1]]$time[PSO_EK_results[,2]], col = "black")
# legend
legend("bottomright", 
       legend=c("Detected saccade onset", "PSO onset (direction inversion)", 
                "PSO onset (minimum velocity)", 
                "PSO offset"),
       col=c("black", "red", "blue", "black"), 
       lty=c("dashed", "solid", "solid", "solid"), cex=1.2)
# y
plot(simulator_results[[1]]$time, simulator_results[[1]]$y, 
     xlab = "Time [ms]", ylab = "Y position [pix]", 
     cex.lab = 1.2, cex.axis = 1.2)
abline(v = simulator_results[[1]]$time[PSO_EK_results[,1]], col = "black", lty = 2)
abline(v = simulator_results[[1]]$time[PSO_EK_results[,8]], col = "red")
abline(v = simulator_results[[1]]$time[PSO_EK_results[,10]], col = "blue")
abline(v = simulator_results[[1]]$time[PSO_EK_results[,2]], col = "black")
par(mfrow=c(1,1)) 

# DETECTION vs GROUND TRUTH
# PSO onset, probably virtually no mismatch
simulator_results[[2]]$t_sacoff_PSO[1:2] # ground truth PSO onset
simulator_results[[1]]$time[PSO_EK_results[,8]] # PSO onset detected by direction-inversion
simulator_results[[1]]$time[PSO_EK_results[,10]] # PSO onset detected by minimum velocity
# PSO offset, probably large mismatch, given the difference in velocity thresholds
simulator_results[[2]]$t_sacoff[1:2] # ground truth PSO offset
simulator_results[[1]]$time[PSO_EK_results[,2]] # PSO offset detected by the EK algorithm
```


## PSO detection using linear classifiers trained on simulation data

As a first step, we take some empirically measured saccade with unknown coding and use our saccade simulator to produce an artificial saccade that looks similar.

```{r, fig.width=16, fig.height=8}
# The Nystrom saccade was collected with these settings here:
samp_freq <- 500
monitor.dist <- 67
monitor.width <- 38
monitor.resx <- 1024
monitor.resy <- 768
screen_center <- data.frame(x = monitor.resx/2, y = monitor.resy/2)
(screen_ppd <- monitor.dist*tan(1*pi/180)/(monitor.width/monitor.resx))

# determine the fixation data from the hand-labeled saccade from above
fixpos_xy_Nystrom <-  matrix(data = c(median(some_sac[time_sacon<0, x]), 
                                      median(some_sac[time_sacon<0, y]), 
                                      sum(diff(some_sac[time_sacoff>0, time])), 
                                      median(some_sac[time_sacoff>0, x]), 
                                      median(some_sac[time_sacoff>0, y]), 
                                      sum(diff(some_sac[time_sacon<=0, time])) ), 
                             nrow = 2, ncol = 3, byrow = TRUE)
# Now, let's simulate a saccade that looks similar
simulated_sac <- saccade_simulator(fixpos_xy = fixpos_xy_Nystrom, 
                                   sac_params = matrix(data = c(1, 2, 0.04, 0.15, 0.035, 0.5, 3, FALSE),
                                                       nrow = 1, ncol = 8, byrow = TRUE), 
                                   fix_params = matrix(data = rep(c(0.01, 10, 0, 0, FALSE), 2), 
                                                       nrow = 2, ncol = 5, byrow = TRUE), 
                                   noise_to_saccades_sd = 0, 
                                   smooth_to_fixation = TRUE,
                                   pix_per_dva = screen_ppd, 
                                   sampling_rate = samp_freq, do_plot = FALSE)  
simulated_sac

# combine original and simulated data
data_orig_long <- melt.data.table(data = some_sac, 
                                  id.vars = c("time", "what"), measure.vars = c("x", "y"), 
                                  variable.name = "coordinate", value.name = "val")
data_orig_long$time <-  data_orig_long$time - data_orig_long$time[1]
data_orig_long$which_data <- "Original data"
data_orig_long$what <- "Unknown"
data_simul_long <- melt.data.table(data = simulated_sac[[1]], 
                                   id.vars = c("time", "what"), measure.vars = c("x", "y"), 
                                   variable.name = "coordinate", value.name = "val")
data_simul_long$which_data <- "Simulated data"
data_both_long <- rbind(data_orig_long, data_simul_long)
# plot both next to each other
ggplot(data = data_both_long, 
       aes(x = time, y = val, color = what, shape = coordinate)) + 
   geom_point(size = 3, alpha = 0.8) + 
   theme_classic(base_size = 18) + 
   theme(legend.position = "bottom", 
         legend.direction = "horizontal") + 
   labs(x = "Time [ms]", y = "Position [pix]", color = "Model-based coding", shape = "Coordinate") + 
   scale_color_viridis_d(option = "B", begin = 0.4, end = 0.8, direction = -1) + 
   facet_wrap(~which_data) 
```

Now we can extract the features. Features and labels of the simulated data can be used for training. The trained classifier will then predict the labels based on the features of the original data.

```{r}
library(LiblineaR) # for the support-vector machines
library(circular) # for direction variance
source("extract_features.R")
use_window_sizes_ms = c(50, 100) # need to specify the widths [ms] of the integration windows

# extract some features from the TEST data
extracted_test_features <- extract_features(x = some_sac$x, 
                                            y = some_sac$y, 
                                            time = some_sac$time, 
                                            pix_per_dva = screen_ppd, 
                                            window_sizes_ms = use_window_sizes_ms, 
                                            do_scale = TRUE) # SVM like scaled data
extracted_test_labels <- some_sac$what # these are the manually coded labels (by Marcus Nystrom)
test_index <- which(complete.cases(extracted_test_features))
head(extracted_test_features[test_index])

# extract some features from the TEST data
extracted_train_features <- extract_features(x = simulated_sac[[1]]$x, 
                                             y = simulated_sac[[1]]$y, 
                                             time = simulated_sac[[1]]$time, 
                                             pix_per_dva = screen_ppd, 
                                             window_sizes_ms = use_window_sizes_ms, 
                                             do_scale = TRUE)
extracted_train_labels <- simulated_sac[[1]]$what # training labels!
train_index <- which(complete.cases(extracted_train_features))
head(extracted_train_features[train_index])

# estimate the best cost of constraints violation heuristically with heuristicC
C_now <- heuristicC(as.matrix(extracted_train_features[train_index, ]))
                                                       
# now train the classifier
trained_classifier <- LiblineaR(data = extracted_train_features[train_index, ], 
                                target = extracted_train_labels[train_index], 
                                type = 2, cost = C_now)

# now lets classifier predict
predicted_classes <- as.character(predict(object = trained_classifier, 
                                          newx = as.matrix(extracted_test_features[test_index, ]) )$predictions)

# show the resulting confusion matrix:
table(extracted_test_labels[test_index], predicted_classes, 
      dnn = c("hand-labeled by Nystrom", "predicted by SVM"))

# show the results
ggplot(data = some_sac[test_index], 
       aes(x = time_sacon, y = dist_sacon, color = predicted_classes, shape = what)) + 
   geom_point(size = 3, alpha = 0.8) + 
   theme_classic() + theme(legend.position = "right", 
                           legend.direction = "vertical") + 
   labs(x = "Time re manually coded saccade onset [ms]", y = "Position [dva]", 
        color = "SVM-predicted labels", shape = "Manually coded labels") + 
   scale_color_viridis_d(option = "B", begin = 0.4, end = 0.8, direction = -1)
```

Now that's lovely, right? 

If any of the techniques described here appeal to you, feel free to use them and cite our book chapter: 
**"Definition, modeling and detection of saccades in the face of post-saccadic oscillations", by Richard Schweitzer and Martin Rolfs**
